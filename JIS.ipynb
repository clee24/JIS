{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clee24/JIS/blob/main/JIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5f0Cxsu5D9F"
      },
      "source": [
        "## Importing Program Dependencies and Alphapose Directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiAnGQTfGJNW"
      },
      "source": [
        "### Installing python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhVtBVEggpm5"
      },
      "outputs": [],
      "source": [
        "! pip install pyyaml\n",
        "! pip install scipy\n",
        "! pip3 install torch torchvision # --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "! pip install pillow\n",
        "! pip install cython_bbox"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaBmrHkYGwjX"
      },
      "source": [
        "### Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXwKoL1cGno4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import yaml, scipy, os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRTX_Lwf7jKL"
      },
      "source": [
        "### Verifying package versions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ToHoYIz7tYT"
      },
      "outputs": [],
      "source": [
        "print(torch.__version__)\n",
        "print(yaml.__version__)\n",
        "print(scipy.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yuaUXJAG2jC"
      },
      "source": [
        "### Downloading and setting up AlphaPose directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK3HvdkZlLJg"
      },
      "outputs": [],
      "source": [
        "# from settings import PROJECT_ROOT\n",
        "!rm -rf /content/AlphaPose\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/MVIG-SJTU/AlphaPose.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJtCBeXpXKLo"
      },
      "source": [
        "### Installing other supporting packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9EHg99klb7_"
      },
      "outputs": [],
      "source": [
        "!python -m pip install cython\n",
        "!sudo apt-get install libyaml-dev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPkeTGTK5SLd"
      },
      "source": [
        "## Running AlphaPose on Clips"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNKUxNyhHVCT"
      },
      "source": [
        "### Initializing AlphaPose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBHRBReold3f"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/AlphaPose')\n",
        "print(os.getcwd())\n",
        "! python setup.py build develop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fonIVYL6HimN"
      },
      "source": [
        "### Downloading pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60eN1JgjlhzA"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "! mkdir /content/AlphaPose/detector/yolo/data\n",
        "file_id = '1D47msNOOiJKvPOXlnpyzdKA3k6E97NTC'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/detector/yolo/data/yolov3-spp.weights')\n",
        "\n",
        "! mkdir /content/AlphaPose/detector/tracker/data\n",
        "file_id = '1nlnuYfGNuHWZztQHXwVZSL_FvfE551pA'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/detector/tracker/data/JDE-1088x608-uncertainty')\n",
        "\n",
        "file_id = '1kQhnMRURFiy7NsdS8EFL-8vtqEXOgECn'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('/content/AlphaPose/pretrained_models/fast_res50_256x192.pth')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x50w5iB936h"
      },
      "outputs": [],
      "source": [
        "!wget -P ./detector/yolox/data/ https://github.com/Megvii-BaseDetection/YOLOX/releases/download/0.1.0/yolox_x.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE582CKQHzuF"
      },
      "source": [
        "Mount Google drive to take input and store output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cP6816ddm7lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geQHeMbBH9Xz"
      },
      "source": [
        "### Processing Clips\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BifxS8MuS--m"
      },
      "source": [
        "To standardize, each video is clipped to 1 second, from the final step to completion of the swing. Additionally, each video is cropped to avoid false identification of other players/pedestrians. Video standardization done manually with DaVinci Resolve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a7uIDuQuiIa"
      },
      "source": [
        "*Note: Add all paths as per your google drive locations\n",
        "* --video /content/drive/MyDrive/JuniorIS/sample_vids/VIDEOX.mp4  //replace your video path\n",
        "* --outdir /content/drive/MyDrive/JuniorIS/sample_vids/vidoutputX  // replace your output path\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZVWB87dTBZz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvyWMoa3ZWR-"
      },
      "source": [
        "Top 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb_fZVjOlm03"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Top1.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Top1Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y2g0trZZXwx"
      },
      "source": [
        "Top 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9D8BowBUufh"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Top2.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Top2Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUWiqBhvZZQK"
      },
      "source": [
        "Top 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkbuM9hBYHUo"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Top3.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Top3Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcm0SKFVZgPi"
      },
      "source": [
        "Top 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56pWjmaWZe8s"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Top4.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Top4Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThVhttiHZjMx"
      },
      "source": [
        "Top 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzUmUTU-ZiP8"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Top5.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Top5Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "695xecd7goWr"
      },
      "source": [
        "Float 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjXtO02iZ4Ry"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Float1.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Float1Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0Ek8907madM"
      },
      "source": [
        "Float 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnxOkQ85mt4Z"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Float2.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Float2Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8XFS3BOmb6Q"
      },
      "source": [
        "Float 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJAZKg0Rm0LA"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Float3.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Float3Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpNXsrP7mdOE"
      },
      "source": [
        "Float 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzMk5k8tm29D"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Float4.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Float4Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLan5toNme-n"
      },
      "source": [
        "Float 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-ke9Y_Nm5AQ"
      },
      "outputs": [],
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Float5.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Float5Folder --save_video --vis_fast"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Float 6"
      ],
      "metadata": {
        "id": "l86BcTm_MBjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MAke sure to point your input video path and output directory\n",
        "os.chdir('/content/AlphaPose')\n",
        "! ls\n",
        "! python3 scripts/demo_inference.py --cfg configs/coco/resnet/256x192_res50_lr1e-3_1x.yaml --checkpoint pretrained_models/fast_res50_256x192.pth --video /content/drive/MyDrive/JuniorIS/sample_vids/Float6.mp4 --outdir /content/drive/MyDrive/JuniorIS/sample_vids/Float6Folder --save_video --vis_fast"
      ],
      "metadata": {
        "id": "5f9XSw19L-2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_qWaNq5uUu"
      },
      "source": [
        "## Output Processing and Random Forest Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS5mAZJMx30r"
      },
      "source": [
        "### Verifying and Prepping Output Data for Manipulation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bws3bNR4XN1i"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_U3hsXAyBvw"
      },
      "outputs": [],
      "source": [
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqLJXhv_Jx0Z"
      },
      "outputs": [],
      "source": [
        "# Path to JSON files\n",
        "top1_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Top1Folder/alphapose-results.json'\n",
        "top2_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Top2Folder/alphapose-results.json'\n",
        "top3_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Top3Folder/alphapose-results.json'\n",
        "top4_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Top4Folder/alphapose-results.json'\n",
        "top5_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Top5Folder/alphapose-results.json'\n",
        "float1_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Float1Folder/alphapose-results.json'\n",
        "float2_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Float2Folder/alphapose-results.json'\n",
        "float3_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Float3Folder/alphapose-results.json'\n",
        "float4_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Float4Folder/alphapose-results.json'\n",
        "float5_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Float5Folder/alphapose-results.json'\n",
        "float6_file_path = '/content/drive/MyDrive/JuniorIS/sample_vids/Float6Folder/alphapose-results.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRguWB0hLV3g"
      },
      "outputs": [],
      "source": [
        "# Loading JSON files\n",
        "with open(top1_file_path, 'r') as json_top1:\n",
        "    top1 = json.load(json_top1)\n",
        "with open(top2_file_path, 'r') as json_top2:\n",
        "    top2 = json.load(json_top2)\n",
        "with open(top3_file_path, 'r') as json_top3:\n",
        "    top3 = json.load(json_top3)\n",
        "with open(top4_file_path, 'r') as json_top4:\n",
        "    top4 = json.load(json_top4)\n",
        "with open(top5_file_path, 'r') as json_top5:\n",
        "    top5 = json.load(json_top5)\n",
        "with open(float1_file_path, 'r') as json_float1:\n",
        "    float1 = json.load(json_float1)\n",
        "with open(float2_file_path, 'r') as json_float2:\n",
        "    float2 = json.load(json_float2)\n",
        "with open(float3_file_path, 'r') as json_float3:\n",
        "    float3 = json.load(json_float3)\n",
        "with open(float4_file_path, 'r') as json_float4:\n",
        "    float4 = json.load(json_float4)\n",
        "with open(float5_file_path, 'r') as json_float5:\n",
        "    float5 = json.load(json_float5)\n",
        "with open(float6_file_path, 'r') as json_float6:\n",
        "    float6 = json.load(json_float6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0wGy4NpLZPX"
      },
      "outputs": [],
      "source": [
        "# Printing json for each serve (data verification step)\n",
        "serves = [top1, top2, top3, top4, top4, float1, float2, float3, float4, float5, float6]\n",
        "count = 1\n",
        "for x in serves:\n",
        "  print(\"serve \" + str(count))\n",
        "  print(x)\n",
        "  count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEcW7iekNj2a"
      },
      "outputs": [],
      "source": [
        "# Creating two arrays for topspin and float serves\n",
        "topserves = [top1, top2, top3, top4, top5]\n",
        "floatserves = [float2, float3, float4, float5, float6]\n",
        "#omitting float1 to test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_N2Kk1s4RHp"
      },
      "source": [
        "### Keypoint Angle Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1MZEzHl4IVJ"
      },
      "source": [
        "Here we are gonna calculate the key angles in each frame for the servers. This will be the data that our classification model ultimately processes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TA_johWQ6_Ka"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "# Keypoint angle calculation\n",
        "def calculate_angle(point1, center_point, point2):\n",
        "    \"\"\"\n",
        "    Calculate the angle between three points.\n",
        "    \"\"\"\n",
        "    v1 = [point1[0] - center_point[0], point1[1] - center_point[1]]\n",
        "    v2 = [point2[0] - center_point[0], point2[1] - center_point[1]]\n",
        "\n",
        "    dot_product = v1[0] * v2[0] + v1[1] * v2[1]\n",
        "    magnitude_v1 = math.sqrt(v1[0] ** 2 + v1[1] ** 2)\n",
        "    magnitude_v2 = math.sqrt(v2[0] ** 2 + v2[1] ** 2)\n",
        "\n",
        "    cos_theta = dot_product / (magnitude_v1 * magnitude_v2)\n",
        "    angle_rad = math.acos(cos_theta)\n",
        "    angle_deg = math.degrees(angle_rad)\n",
        "\n",
        "    return angle_deg\n",
        "\n",
        "# Defining keypoint indices based on COCO ordering pulled from AlphaPose documentation\n",
        "shoulder_idx = 6  # LShoulder\n",
        "hip_idx = 12      # RHip\n",
        "wrist_idx = 10    # RWrist\n",
        "\n",
        "# Initializing empty lists to store backswing angles and labels\n",
        "backswing_angles = []\n",
        "labels = []\n",
        "\n",
        "# Iterating through each topspin serve JSON entry\n",
        "i = 1\n",
        "for x in topserves:\n",
        "  print(\"top\" + str(i) + \":\")\n",
        "  for frame_data in x:\n",
        "      keypoints = frame_data[\"keypoints\"]\n",
        "\n",
        "      shoulder = keypoints[shoulder_idx * 3 : shoulder_idx * 3 + 2]\n",
        "      hip = keypoints[hip_idx * 3 : hip_idx * 3 + 2]\n",
        "      wrist = keypoints[wrist_idx * 3 : wrist_idx * 3 + 2]\n",
        "      # keypoint coordinates\n",
        "\n",
        "      backswing_angle = calculate_angle(shoulder, hip, wrist)\n",
        "      print(\"backswing angle:\", backswing_angle)\n",
        "      # backswing shoulder angle\n",
        "\n",
        "  i += 1\n",
        "  print()\n",
        "\n",
        "# Iterating through each float serve JSON entry\n",
        "l = 1\n",
        "for x in floatserves:\n",
        "  print(\"float\" + str(l) + \":\")\n",
        "  for frame_data in x:\n",
        "      keypoints = frame_data[\"keypoints\"]\n",
        "\n",
        "      # keypoint coordinates\n",
        "      shoulder = keypoints[shoulder_idx * 3 : shoulder_idx * 3 + 2]\n",
        "      hip = keypoints[hip_idx * 3 : hip_idx * 3 + 2]\n",
        "      wrist = keypoints[wrist_idx * 3 : wrist_idx * 3 + 2]\n",
        "\n",
        "      backswing_angle = calculate_angle(shoulder, hip, wrist)\n",
        "      print(\"backswing angle:\", backswing_angle)\n",
        "      # backswing shoulder angle\n",
        "\n",
        "  l += 1\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtUqRsJXRXa2"
      },
      "source": [
        "### Random Forest Classification Model Using Sequences of Backswing Angles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZO4Q57ioSSP"
      },
      "source": [
        "Prepping Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9MsbjKljvQ3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#for padding\n",
        "\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "# Iterating through each topspin serve JSON entry\n",
        "for serve in topserves:\n",
        "    serve_sequence = []\n",
        "    for frame_data in serve:\n",
        "        keypoints = frame_data[\"keypoints\"]\n",
        "\n",
        "        shoulder = keypoints[shoulder_idx * 3 : shoulder_idx * 3 + 2]\n",
        "        hip = keypoints[hip_idx * 3 : hip_idx * 3 + 2]\n",
        "        wrist = keypoints[wrist_idx * 3 : wrist_idx * 3 + 2]\n",
        "        # keypoint coordinates\n",
        "\n",
        "        backswing_angle = calculate_angle(shoulder, hip, wrist)\n",
        "        # backswing shoulder angle\n",
        "\n",
        "        serve_sequence.append(backswing_angle)\n",
        "        # appending to serve sequence\n",
        "\n",
        "    sequences.append(serve_sequence)\n",
        "    #appending sequence to list\n",
        "\n",
        "    labels.append(0)\n",
        "    #appending topspin label\n",
        "\n",
        "# Iterate through each float serve JSON entry\n",
        "for serve in floatserves:\n",
        "    serve_sequence = []\n",
        "    for frame_data in serve:\n",
        "        keypoints = frame_data[\"keypoints\"]\n",
        "\n",
        "        shoulder = keypoints[shoulder_idx * 3 : shoulder_idx * 3 + 2]\n",
        "        hip = keypoints[hip_idx * 3 : hip_idx * 3 + 2]\n",
        "        wrist = keypoints[wrist_idx * 3 : wrist_idx * 3 + 2]\n",
        "        # keypoint coordinates\n",
        "\n",
        "        backswing_angle = calculate_angle(shoulder, hip, wrist)\n",
        "        # backswing shoulder angle\n",
        "\n",
        "        serve_sequence.append(backswing_angle)\n",
        "        # appending to serve sequence\n",
        "\n",
        "    sequences.append(serve_sequence)\n",
        "     #appending sequence to list\n",
        "\n",
        "    labels.append(1)\n",
        "    #appending topspin label\n",
        "\n",
        "# formatting\n",
        "X = pad_sequences(sequences, padding='post', dtype='float32')\n",
        "y = np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5WQ2eBB7Uh4"
      },
      "source": [
        "Training Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKgfMzcU7S02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e455851-499b-43bd-f819-96de7a4fcd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "# splitting training/testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# finding best parameters using GridSearchCV\n",
        "rf_classifier = RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200, random_state=42)\n",
        "\n",
        "# training\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# predicting\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Random Forest Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT94va1UoOsi"
      },
      "source": [
        "Classification of Float1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMufdapUj3Hs",
        "outputId": "7e977267-60a3-438d-b236-3f2ce6adcbe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The serve is classified as a 'float' serve.\n"
          ]
        }
      ],
      "source": [
        "#processing data\n",
        "new_sequence = []\n",
        "for frame_data in float1:\n",
        "    keypoints = frame_data[\"keypoints\"]\n",
        "\n",
        "    shoulder = keypoints[shoulder_idx * 3 : shoulder_idx * 3 + 2]\n",
        "    hip = keypoints[hip_idx * 3 : hip_idx * 3 + 2]\n",
        "    wrist = keypoints[wrist_idx * 3 : wrist_idx * 3 + 2]\n",
        "\n",
        "    backswing_angle = calculate_angle(shoulder, hip, wrist)\n",
        "\n",
        "    new_sequence.append(backswing_angle)\n",
        "\n",
        "# padding\n",
        "max_len = len(max(sequences, key=len))\n",
        "new_padded_sequence = pad_sequences([new_sequence], maxlen=max_len, padding='post', dtype='float32')\n",
        "\n",
        "# prediction\n",
        "prediction = rf_classifier.predict(new_padded_sequence)\n",
        "if prediction == 0:\n",
        "    print(\"The serve is classified as a 'top' serve.\")\n",
        "else:\n",
        "    print(\"The serve is classified as a 'float' serve.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "k_N2Kk1s4RHp"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}